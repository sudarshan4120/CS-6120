{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e28f7c45-f3f5-45b8-8b41-5012bc57d4bd",
   "metadata": {
    "id": "e28f7c45-f3f5-45b8-8b41-5012bc57d4bd"
   },
   "source": [
    "Homework 3: Sentiment Analysis\n",
    "----\n",
    "\n",
    "The following instructions apply to all notebooks and `.py` files you submit for this homework.\n",
    "\n",
    "Due date: April 15th, 2024 11:59 PM (EST)\n",
    "\n",
    "Total Points: (105)\n",
    "- Task 0: 05 points\n",
    "- Task 1: 10 points\n",
    "- Task 2: 20 points\n",
    "- Task 3: 25 points\n",
    "- Task 4: 40 points (question in LSTM_EncDec.ipynb)\n",
    "\n",
    "Goals:\n",
    "- understand the difficulties of counting and probabilities in NLP applications\n",
    "- work with real world data using different approaches to classification\n",
    "- stress test your model (to some extent)\n",
    "\n",
    "\n",
    "Allowed python modules:\n",
    "- `numpy`, `matplotlib`, `keras`, `pytorch`, `nltk`, `pandas`, `sci-kit learn` (`sklearn`), `seaborn`, and all built-in python libraries (e.g. `math` and `string`)\n",
    "- if you would like to use a library not on this list, please check with us on Campuswire first.\n",
    "- all *necessary* imports have been included for you (all imports that we used in our solution)\n",
    "\n",
    "Instructions:\n",
    "- Complete outlined problems in this notebook.\n",
    "- When you have finished, __clear the kernel__ and __run__ your notebook \"fresh\" from top to bottom. Ensure that there are __no errors__.\n",
    "    - If a problem asks for you to write code that does result in an error (as in, the answer to the problem is an error), leave the code in your notebook but commented out so that running from top to bottom does not result in any errors.\n",
    "- Double check that you have completed Task 0.\n",
    "- Submit your work on Gradescope.\n",
    "- Double check that your submission on Gradescope looks like you believe it should."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc3f1aa-6b6e-4953-a30d-a79ab0794170",
   "metadata": {
    "id": "cfc3f1aa-6b6e-4953-a30d-a79ab0794170"
   },
   "source": [
    "Names & Sections\n",
    "----\n",
    "Names: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4307e0-20b7-4ed3-9fa0-086f899b4583",
   "metadata": {
    "id": "2a4307e0-20b7-4ed3-9fa0-086f899b4583"
   },
   "source": [
    "Task 0: Name, References, Reflection (5 points)\n",
    "---\n",
    "\n",
    "References\n",
    "---\n",
    "List the resources you consulted to complete this homework here. Write one sentence per resource about what it provided to you. If you consulted no references to complete your assignment, write a brief sentence stating that this is the case and why it was the case for you.\n",
    "\n",
    "- Python and PyTorch documentations.\n",
    "- Lecture notes and slides for revising the concepts.\n",
    "- Youtube for concept related content.\n",
    "\n",
    "(Example)\n",
    "- https://docs.python.org/3/tutorial/datastructures.html\n",
    "    - Read about the the basics and syntax for data structures in python.\n",
    "\n",
    "AI Collaboration\n",
    "---\n",
    "Following the *Policy on the use of Generative AI* in the syllabus, please cite any LLMs that you used here and briefly describe what you used them for, including to improve language clarity in the written sections.\n",
    "\n",
    "Reflection\n",
    "----\n",
    "Answer the following questions __after__ you complete this assignment (no more than 1 sentence per question required, this section is graded on completion):\n",
    "\n",
    "1. Does this work reflect your best effort? \n",
    "- Yes\n",
    "2. What was/were the most challenging part(s) of the assignment? \n",
    "- Finetuning the LSTM and data preprocessing\n",
    "3. If you want feedback, what function(s) or problem(s) would you like feedback on and why? \n",
    "- Feedback on how best to debug training issues and the solutions.\n",
    "4. Briefly reflect on how your partnership functioned--who did which tasks, how was the workload on each of you individually as compared to the previous homeworks, etc. \n",
    "- Individual Assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669c4773-456b-4d5a-bdce-df7bbcb3d16b",
   "metadata": {
    "id": "669c4773-456b-4d5a-bdce-df7bbcb3d16b"
   },
   "source": [
    "Task 1: Provided Data Write-Up (10 points)\n",
    "---\n",
    "\n",
    "Every time you use a data set in an NLP application (or in any software application), you should be able to answer a set of questions about that data. Answer these now. Default to no more than 1 sentence per question needed. If more explanation is necessary, do give it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c281567d-b99b-45df-8b1b-2b0e35cb9196",
   "metadata": {
    "id": "c281567d-b99b-45df-8b1b-2b0e35cb9196"
   },
   "source": [
    "This is about the __provided__ movie review data set.\n",
    "\n",
    "1. Where did you get the data from? The provided dataset(s) were sub-sampled from https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
    "2. (1 pt) How was the data collected (where did the people acquiring the data get it from and how)? \n",
    "3. (2 pts) How large is the dataset (answer for both the train and the dev set, separately)? (# reviews, # tokens in both the train and dev sets)\n",
    "4. (1 pt) What is your data? (i.e. newswire, tweets, books, blogs, etc)\n",
    "5. (1 pt) Who produced the data? (who were the authors of the text? Your answer might be a specific person or a particular group of people)\n",
    "6. (2 pts) What is the distribution of labels in the data (answer for both the train and the dev set, separately)?\n",
    "7. (2 pts) How large is the vocabulary (answer for both the train and the dev set, separately)?\n",
    "8. (1 pt) How big is the overlap between the vocabulary for the train and dev set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a2c3dd",
   "metadata": {},
   "source": [
    "1. The provided dataset(s) were sub-sampled from https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews.\n",
    "2. Data was collected from IMDb by restricting to a maximum of 30 reviews per movie to avoid correlated ratings and ensuring equal number of negative and positive reviews in the whole dataset.\n",
    "3. Reviews: Train-1600, dev-200. Tokens: Train-425345, Dev-54599. (Tokenized using word_tokenize from nltk).\n",
    "4. The data comprises user-submitted text movie reviews with the sentiment labels as positive/negative.\n",
    "5. Authors of the text were the users who posted the reviews on IMDB, the dataset was put together by {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher} (Ref: https://ai.stanford.edu/~amaas/data/sentiment/)\n",
    "6. Train: Positive-804, Negative-796. Dev: Positive-105, Negative-95.\n",
    "7. Vocab size: Train-30705 , Dev-8953. (Based on nltk word_tokenize).\n",
    "8. Overlap between train and dev vocab: 6574."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ad53677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afcaa396",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file = 'movie_reviews_train.txt'\n",
    "train_df = pd.read_csv(train_data_file, sep='\\t', header=None, names=['id', 'review', 'label'])[['review', 'label']]\n",
    "X_train, y_train = train_df['review'].values, train_df['label'].values\n",
    "\n",
    "dev_data_file = 'movie_reviews_dev.txt'\n",
    "dev_df = pd.read_csv(dev_data_file, sep='\\t', header=None, names=['id', 'review', 'label'])[['review', 'label']]\n",
    "X_dev, y_dev = dev_df['review'].values, dev_df['label'].values\n",
    "\n",
    "test_data_file = 'movie_reviews_test.txt'\n",
    "test_df = pd.read_csv(test_data_file, sep='\\t', header=None, names=['id', 'review', 'label'])[['review', 'label']]\n",
    "X_test, y_test = test_df['review'].values, test_df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f8ef539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600 entries, 0 to 1599\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   review  1600 non-null   object\n",
      " 1   label   1600 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 25.1+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   review  200 non-null    object\n",
      " 1   label   200 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.3+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()\n",
    "dev_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f01206d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in train data: 425345\n",
      "Number of tokens in dev data: 54599\n",
      "Number of vocab in train data: 30705\n",
      "Number of vocab in dev data: 8953\n",
      "Overlap between train and dev vocab: 6574\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "def num_tokens(data):\n",
    "    vocab = set()\n",
    "    num_tokens = 0\n",
    "    for doc in data:\n",
    "        tokens = word_tokenize(doc)\n",
    "        num_tokens += len(tokens)\n",
    "        vocab.update(tokens)\n",
    "    return num_tokens, len(vocab), vocab\n",
    "\n",
    "train_num_tokens, train_num_vocab, train_vocab = num_tokens(X_train)\n",
    "dev_num_tokens, dev_num_vocab, dev_vocab = num_tokens(X_dev)\n",
    "print('Number of tokens in train data:', train_num_tokens)\n",
    "print('Number of tokens in dev data:', dev_num_tokens)\n",
    "print('Number of vocab in train data:', train_num_vocab)\n",
    "print('Number of vocab in dev data:', dev_num_vocab)\n",
    "\n",
    "print('Overlap between train and dev vocab:', len(train_vocab & dev_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9f3adbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of labels in train data:\n",
      "label\n",
      "1    804\n",
      "0    796\n",
      "Name: count, dtype: int64\n",
      "Distribution of labels in dev data:\n",
      "label\n",
      "1    105\n",
      "0     95\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Distribution of labels in train data:')\n",
    "print(train_df['label'].value_counts())\n",
    "print('Distribution of labels in dev data:')\n",
    "print(dev_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d64fd8f-f130-4f1b-8624-c151c502344b",
   "metadata": {
    "id": "2d64fd8f-f130-4f1b-8624-c151c502344b"
   },
   "source": [
    "Task 2: Train a Logistic Regression Model (20 points)\n",
    "----\n",
    "1. Implement a custom function to read in a dataset, and return a list of tuples, using the Tf-Idf feature extraction technique.\n",
    "2. Compare your implementation to `sklearn`'s TfidfVectorizer (imported below) by timing both on the provided datasets using the time module.\n",
    "3. Using each set of features, and `sklearn`'s implementation of `LogisticRegression`, train a machine learning model to predict sentiment on the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e9bbb93-9a5d-4326-8dd0-d2ffcf242123",
   "metadata": {
    "id": "0e9bbb93-9a5d-4326-8dd0-d2ffcf242123"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter, defaultdict\n",
    "import time\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62c515ae-3637-42b6-9412-e0710e7821bb",
   "metadata": {
    "id": "62c515ae-3637-42b6-9412-e0710e7821bb"
   },
   "outputs": [],
   "source": [
    "# The following function reads a data-file and splits the contents by tabs.\n",
    "# The first column is an ID, and thus is discarded. The second column consists of the actual reviews data.\n",
    "# The third column is the true label for each data point.\n",
    "\n",
    "# The function returns two objects - a list of all reviews, and a numpy array of labels.\n",
    "# You will need to use this function later.\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "def get_lists(input_file):\n",
    "    f=open(input_file, 'r')\n",
    "    lines = [line.split('\\t')[1:] for line in f.readlines()]\n",
    "    X = [row[0] for row in lines]\n",
    "    y=np.array([int(row[1]) for row in lines])\n",
    "    return X, y\n",
    "\n",
    "# Fill in the following function to take a corpus (list of reviews) as input,\n",
    "# extract TfIdf values and return an array of features and the vocabulary.\n",
    "\n",
    "# If the vocabulary argument is supplied, then the function should only convert the input corpus\n",
    "# to feature vectors using the provided vocabulary and the max_features argument (if not None).\n",
    "# In this case, the function should return feature vectors and the supplied vocabulary.\n",
    "\n",
    "# If the max_features parameter is set to None, then all words in the corpus should be used.\n",
    "# If the max_features parameter is specified (say, k),\n",
    "# then only use the k most frequent words in the corpus to build your vocabulary.\n",
    "\n",
    "# The function should return two things.\n",
    "\n",
    "# The first object should be a numpy array of shape (n_documents, vocab_size),\n",
    "# which contains the TF-IDF feature vectors for each document.\n",
    "\n",
    "# The second object should be a dictionary of the words in the vocabulary,\n",
    "# mapped to their corresponding index in alphabetical sorted order.\n",
    "\n",
    "def get_tfidf_vectors(token_lists, max_features=None, vocabulary=None):\n",
    "    def tokenize(text):\n",
    "        return text.lower().split()\n",
    "\n",
    "    if vocabulary is None:\n",
    "        df = defaultdict(int)\n",
    "        document_tokens = []\n",
    "        for tokens in token_lists:\n",
    "            tokens = tokenize(tokens)\n",
    "            document_tokens.append(tokens)\n",
    "            unique_tokens = set(tokens)\n",
    "            for token in unique_tokens:\n",
    "                df[token] += 1\n",
    "\n",
    "        if max_features is not None:\n",
    "            sorted_vocab = sorted(df.items(), key=lambda item: item[1], reverse=True)[:max_features]\n",
    "            vocabulary = {word: i for i, (word, _) in enumerate(sorted_vocab)}\n",
    "        else:\n",
    "            vocabulary = {word: i for i, word in enumerate(sorted(df.keys()))}\n",
    "\n",
    "        idf = {word: math.log(len(token_lists) / (df[word] + 1)) for word, _ in vocabulary.items()}\n",
    "    else:\n",
    "        document_tokens = [tokenize(tokens) for tokens in token_lists]\n",
    "        idf = {word: math.log(len(token_lists) / (sum(1 for tokens in document_tokens if word in tokens) + 1)) for word in vocabulary}\n",
    "\n",
    "    tfidf_matrix = np.zeros((len(token_lists), len(vocabulary)))\n",
    "    for idx, tokens in enumerate(document_tokens):\n",
    "        tf = Counter(tokens)\n",
    "        for word, count in tf.items():\n",
    "            if word in vocabulary:\n",
    "                tfidf_matrix[idx, vocabulary[word]] = (count / len(tokens)) * idf[word]\n",
    "\n",
    "    return tfidf_matrix, vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62226f12-d0e5-4e74-887e-5cd852b96707",
   "metadata": {
    "id": "62226f12-d0e5-4e74-887e-5cd852b96707"
   },
   "source": [
    "We will now compare the runtime of our Tf-Idf implementation to the `sklearn` implementation. Call the respective functions with appropriate arguments in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2e6c726-0e12-4e1f-8c8b-146a9a506a3f",
   "metadata": {
    "id": "e2e6c726-0e12-4e1f-8c8b-146a9a506a3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by custom TF-IDF:  0.3812687397003174  seconds\n",
      "Time taken by sklearn's TF-IDF:  0.20406103134155273  seconds\n"
     ]
    }
   ],
   "source": [
    "# define constants for the files we are using\n",
    "TRAIN_FILE = \"movie_reviews_train.txt\"\n",
    "TEST_FILE = \"movie_reviews_test.txt\"\n",
    "\n",
    "train_corpus, y_train = get_lists(TRAIN_FILE)\n",
    "test_corpus, y_test = get_lists(TEST_FILE)\n",
    "\n",
    "# First we will use our custom vectorizer to convert words to features, and time it.\n",
    "\n",
    "start = time.time()\n",
    "X_train_custom, vocab_custom = get_tfidf_vectors(train_corpus)\n",
    "end = time.time()\n",
    "print(\"Time taken by custom TF-IDF: \", end-start, \" seconds\")\n",
    "\n",
    "# Next we will use sklearn's TfidfVectorizer to load in the data, and time it.\n",
    "\n",
    "sklearn_vectorizer = TfidfVectorizer()\n",
    "start = time.time()\n",
    "X_train_sklearn = sklearn_vectorizer.fit_transform(train_corpus)\n",
    "end = time.time()\n",
    "print(\"Time taken by sklearn's TF-IDF: \", end-start, \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35afb9c6",
   "metadata": {},
   "source": [
    "NOTE: Ideally, your vectorizer should be within one order of magnitude of the sklearn implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bdbf31c-bf6b-4ab4-b87b-47dd7c5468a8",
   "metadata": {
    "id": "8bdbf31c-bf6b-4ab4-b87b-47dd7c5468a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size of custom vectorizer for train set: 44077\n",
      "Vocab size of sklearn vectorizer for train set: 22684\n",
      "Sparsity in Train (custom): 99.66601770764798 %\n",
      "Sparsity in Train (sklearn): 99.39492318374185 %\n"
     ]
    }
   ],
   "source": [
    "# Any additional code needed to answer questions below.\n",
    "print('Vocab size of custom vectorizer for train set:', len(vocab_custom))\n",
    "print('Vocab size of sklearn vectorizer for train set:', len(sklearn_vectorizer.vocabulary_))\n",
    "\n",
    "non_zero_elements_custom = np.count_nonzero(X_train_custom)\n",
    "total_elements_custom = X_train_custom.shape[0] * X_train_custom.shape[1]\n",
    "sparsity_custom = 100 * (1 - (non_zero_elements_custom / total_elements_custom))\n",
    "\n",
    "sparsity_sklearn = 100 * (1 - (X_train_sklearn.nnz / (X_train_sklearn.shape[0] * X_train_sklearn.shape[1])))\n",
    "print(\"Sparsity in Train (custom):\", sparsity_custom, \"%\")\n",
    "print(\"Sparsity in Train (sklearn):\", sparsity_sklearn, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6463f022-7433-4397-88ed-eed8b01b1a45",
   "metadata": {
    "id": "6463f022-7433-4397-88ed-eed8b01b1a45"
   },
   "source": [
    "1. How large is the vocabulary generated by your vectorizer?<br> \n",
    "- Vocab size of custom vectorizer: 44077\n",
    "2. How large is the vocabulary generated by the `sklearn` TfidfVectorizer?<br>\n",
    "- Vocab size of sklearn vectorizer: 22684\n",
    "3. Where might these differences be coming from?<br> \n",
    "- Differences might be coming from different tokenization methods or different handling of case sensitivity.\n",
    "4. What steps did you take to ensure your vectorizer is optimized for best possible runtime?<br> \n",
    "- Used defaultdict for efficient counting.\n",
    "- Avoided redundant computations by caching results when possible.\n",
    "5. How sparse are your custom features (average percentage of features per review that are zero)?<br>\n",
    "- Sparsity (custom): 99.66601770764798 %\n",
    "6. How sparse are the TfidfVectorizer's features?<br> \n",
    "- Sparsity (sklearn): 99.39492318374185 %"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38f496b",
   "metadata": {},
   "source": [
    "NOTE: if you set the lowercase option to False, the sklearn vectorizer should have a vocabulary of around 50k words/tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c76612-4dd4-489c-90e4-0c38029c32d1",
   "metadata": {
    "id": "09c76612-4dd4-489c-90e4-0c38029c32d1"
   },
   "source": [
    "**Logistic Regression**\n",
    "\n",
    "Now, we will compare how our custom features stack up against sklearn's TfidfVectorizer, by training two separate Logistic Regression classifiers - one on each set of feature vectors. Then load the test set, and convert it to two sets of feature vectors, one using our custom vectorizer (to do this, provide the vocabulary as a function argument), and one using sklearn's Tfidf (use the same object as before to transform the test inputs). For both classifiers, print the average accuracy on the test set and the F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68eb6d36-1e71-4665-aab4-1217a42e6dcc",
   "metadata": {
    "id": "68eb6d36-1e71-4665-aab4-1217a42e6dcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom TF-IDF Features:\n",
      "Accuracy: 0.8\n",
      "F1 Score: 0.8290598290598291\n",
      "\n",
      "Sklearn TfidfVectorizer Features:\n",
      "Accuracy: 0.775\n",
      "F1 Score: 0.7906976744186046\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# First use sklearn's LogisticRegression classifier to do sentiment analysis using your custom feature vectors:\n",
    "X_train_custom, vocab_custom = get_tfidf_vectors(train_corpus)\n",
    "lr_custom = LogisticRegression()\n",
    "lr_custom.fit(X_train_custom, y_train)\n",
    "\n",
    "# Load the test data, extract features using your custom vectorizer, and test the performance of the LR classifier\n",
    "X_test_custom, _ = get_tfidf_vectors(test_corpus, vocabulary=vocab_custom)\n",
    "y_pred_custom = lr_custom.predict(X_test_custom)\n",
    "accuracy_custom = accuracy_score(y_test, y_pred_custom)\n",
    "f1_custom = f1_score(y_test, y_pred_custom)\n",
    "\n",
    "# Print the accuracy of your model on the test data\n",
    "print(\"Custom TF-IDF Features:\")\n",
    "print(\"Accuracy:\", accuracy_custom)\n",
    "print(\"F1 Score:\", f1_custom)\n",
    "\n",
    "# Now repeat the above steps, but this time using features extracted by sklearn's Tfidfvectorizer\n",
    "sklearn_vectorizer = TfidfVectorizer()\n",
    "X_train_sklearn = sklearn_vectorizer.fit_transform(train_corpus)\n",
    "lr_sklearn = LogisticRegression()\n",
    "lr_sklearn.fit(X_train_sklearn, y_train)\n",
    "\n",
    "X_test_sklearn = sklearn_vectorizer.transform(test_corpus)\n",
    "y_pred_sklearn = lr_sklearn.predict(X_test_sklearn)\n",
    "accuracy_sklearn = accuracy_score(y_test, y_pred_sklearn)\n",
    "f1_sklearn = f1_score(y_test, y_pred_sklearn)\n",
    "\n",
    "print(\"\\nSklearn TfidfVectorizer Features:\")\n",
    "print(\"Accuracy:\", accuracy_sklearn)\n",
    "print(\"F1 Score:\", f1_sklearn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5679888",
   "metadata": {},
   "source": [
    "NOTE: we're expecting to see a F1 score of around 80% using both your custom features and the sklearn features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0220a93-ba22-411a-962f-983ffe3a34f2",
   "metadata": {
    "id": "f0220a93-ba22-411a-962f-983ffe3a34f2"
   },
   "source": [
    "Finally, repeat the process (training and testing), but this time, set the max_features argument to 1000 for both our custom vectorizer and sklearn's Tfidfvectorizer. Report average accuracy and F1 scores for both classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f995a09c-0447-422d-8b37-e9120cfadfab",
   "metadata": {
    "id": "f995a09c-0447-422d-8b37-e9120cfadfab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom TF-IDF Features:\n",
      "Accuracy: 0.78\n",
      "F1 Score: 0.8135593220338984\n",
      "Sklearn TfidfVectorizer Features:\n",
      "Accuracy: 0.78\n",
      "F1 Score: 0.7981651376146789\n"
     ]
    }
   ],
   "source": [
    "max_features = 1000\n",
    "# First use sklearn's LogisticRegression classifier to do sentiment analysis using your custom feature vectors:\n",
    "X_train_custom, vocab_custom = get_tfidf_vectors(train_corpus, max_features=max_features)\n",
    "lr_custom = LogisticRegression()\n",
    "lr_custom.fit(X_train_custom, y_train)\n",
    "\n",
    "\n",
    "# Load the test data, extract features using your custom vectorizer, and test the performance of the LR classifier\n",
    "X_test_custom, _ = get_tfidf_vectors(test_corpus, vocabulary=vocab_custom)\n",
    "y_pred_custom = lr_custom.predict(X_test_custom)\n",
    "accuracy_custom = accuracy_score(y_test, y_pred_custom)\n",
    "f1_custom = f1_score(y_test, y_pred_custom)\n",
    "\n",
    "\n",
    "# Print the accuracy of your model on the test data\n",
    "print(\"Custom TF-IDF Features:\")\n",
    "print(\"Accuracy:\", accuracy_custom)\n",
    "print(\"F1 Score:\", f1_custom)\n",
    "\n",
    "# Now repeat the above steps, but this time using features extracted by sklearn's Tfidfvectorizer\n",
    "sklearn_vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "X_train_sklearn = sklearn_vectorizer.fit_transform(train_corpus)\n",
    "lr_sklearn = LogisticRegression()\n",
    "lr_sklearn.fit(X_train_sklearn, y_train)\n",
    "\n",
    "X_test_sklearn = sklearn_vectorizer.transform(test_corpus)\n",
    "y_pred_sklearn = lr_sklearn.predict(X_test_sklearn)\n",
    "accuracy_sklearn = accuracy_score(y_test, y_pred_sklearn)\n",
    "f1_sklearn = f1_score(y_test, y_pred_sklearn)\n",
    "\n",
    "print(\"Sklearn TfidfVectorizer Features:\")\n",
    "print(\"Accuracy:\", accuracy_sklearn)\n",
    "print(\"F1 Score:\", f1_sklearn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2858e409-8a87-43aa-8646-1e5419cce6db",
   "metadata": {
    "id": "2858e409-8a87-43aa-8646-1e5419cce6db"
   },
   "source": [
    "1. Is there a stark difference between the two vectorizers with 1000 features?\n",
    "- No, there isn't a stark difference between the two vectorizers when limited to 1000 features; both show very similar accuracy and F1 scores.\n",
    "2. Use sklearn's documentation for the Tfidfvectorizer to figure out what may be causing the performance difference (or lack thereof).<br>\n",
    "- The similar performance is likely because both vectorizers are good at identifying and using the top 1000 most important words for sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68df8d77",
   "metadata": {},
   "source": [
    "NOTE: Irrespective of your conclusions, both implementations should be above 60% F1 Score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c652f8ab-3893-4021-b33f-c466b2e1d98a",
   "metadata": {
    "id": "c652f8ab-3893-4021-b33f-c466b2e1d98a"
   },
   "source": [
    "Task 3: Train a Feedforward Neural Network Model (25 points)\n",
    "----\n",
    "1. Using PyTorch, implement a feedforward neural network to do sentiment analysis. This model should take sparse vectors of length 10000 as input (note this is 10000, not 1000), and have a single output with the sigmoid activation function. The number of hidden layers, and intermediate activation choices are up to you, but please make sure your model does not take more than ~1 minute to train.\n",
    "2. Evaluate the model using PyTorch functions for average accuracy, area under the ROC curve and F1 scores (see [torcheval](https://pytorch.org/torcheval/stable/)) using both vectorizers, with max_features set to 10000 in both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f563ec2-d02a-4176-908c-011acd8851de",
   "metadata": {
    "id": "3f563ec2-d02a-4176-908c-011acd8851de"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# if torch.backends.mps.is_available():\n",
    "# \tdevice = torch.device(\"mps\")\n",
    "if torch.cuda.is_available():\n",
    "\tdevice = torch.device(\"cuda\")\n",
    "else:\n",
    "\tdevice = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcb6aa45-e33a-4d08-bff8-996e1f80dad2",
   "metadata": {
    "id": "fcb6aa45-e33a-4d08-bff8-996e1f80dad2"
   },
   "outputs": [],
   "source": [
    "class feedforward(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10000, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = torch.sigmoid(self.fc3(X))\n",
    "        return X\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            return self(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba08e134-2a81-48b9-89c3-43046be4cc1b",
   "metadata": {
    "id": "ba08e134-2a81-48b9-89c3-43046be4cc1b"
   },
   "outputs": [],
   "source": [
    "# Load the data using custom and sklearn vectors\n",
    "train_corpus, y_train = get_lists(TRAIN_FILE)\n",
    "test_corpus, y_test = get_lists(TEST_FILE)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_train_sklearn = vectorizer.fit_transform(train_corpus)\n",
    "X_test_sklearn = vectorizer.transform(test_corpus)\n",
    "\n",
    "X_train_custom, vocab_custom = get_tfidf_vectors(train_corpus, max_features=10000)\n",
    "X_test_custom, _ = get_tfidf_vectors(test_corpus, vocabulary=vocab_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "237cbc15-3473-427d-8d3f-af1059f736b4",
   "metadata": {
    "id": "237cbc15-3473-427d-8d3f-af1059f736b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with custom features\n",
      "Epoch 1/50, Loss: 0.6897892951965332\n",
      "Epoch 2/50, Loss: 0.613271951675415\n",
      "Epoch 3/50, Loss: 0.44274917244911194\n",
      "Epoch 4/50, Loss: 0.20252814888954163\n",
      "Epoch 5/50, Loss: 0.0660819560289383\n",
      "Epoch 6/50, Loss: 0.04162602871656418\n",
      "Epoch 7/50, Loss: 0.01783471181988716\n",
      "Epoch 8/50, Loss: 0.009572441689670086\n",
      "Epoch 9/50, Loss: 0.0068570408038794994\n",
      "Epoch 10/50, Loss: 0.0056688860058784485\n",
      "Epoch 11/50, Loss: 0.0029908674769103527\n",
      "Epoch 12/50, Loss: 0.0025128794368356466\n",
      "Epoch 13/50, Loss: 0.0018601553747430444\n",
      "Epoch 14/50, Loss: 0.0014964134898036718\n",
      "Epoch 15/50, Loss: 0.0011987502221018076\n",
      "Epoch 16/50, Loss: 0.0007872257847338915\n",
      "Epoch 17/50, Loss: 0.0007478757761418819\n",
      "Epoch 18/50, Loss: 0.0005511886556632817\n",
      "Epoch 19/50, Loss: 0.0004044831730425358\n",
      "Epoch 20/50, Loss: 0.0004165777354501188\n",
      "Epoch 21/50, Loss: 0.0004099368234165013\n",
      "Epoch 22/50, Loss: 0.00027319847140461206\n",
      "Epoch 23/50, Loss: 0.0002583259192761034\n",
      "Epoch 24/50, Loss: 0.00026254975819028914\n",
      "Epoch 25/50, Loss: 0.0002131522196577862\n",
      "Epoch 26/50, Loss: 0.00014626455958932638\n",
      "Epoch 27/50, Loss: 0.00012573276762850583\n",
      "Epoch 28/50, Loss: 0.0001325809134868905\n",
      "Epoch 29/50, Loss: 0.00010368195944465697\n",
      "Epoch 30/50, Loss: 8.221907773986459e-05\n",
      "Epoch 31/50, Loss: 7.91060519986786e-05\n",
      "Epoch 32/50, Loss: 9.07087596715428e-05\n",
      "Epoch 33/50, Loss: 9.045935439644381e-05\n",
      "Epoch 34/50, Loss: 5.6437827879562974e-05\n",
      "Epoch 35/50, Loss: 5.112640428706072e-05\n",
      "Epoch 36/50, Loss: 6.259954534471035e-05\n",
      "Epoch 37/50, Loss: 6.755677168257535e-05\n",
      "Epoch 38/50, Loss: 5.284341023070738e-05\n",
      "Epoch 39/50, Loss: 5.168841016711667e-05\n",
      "Epoch 40/50, Loss: 3.463829489191994e-05\n",
      "Epoch 41/50, Loss: 4.571274621412158e-05\n",
      "Epoch 42/50, Loss: 4.2380015656817704e-05\n",
      "Epoch 43/50, Loss: 4.066599649377167e-05\n",
      "Epoch 44/50, Loss: 3.5401826607994735e-05\n",
      "Epoch 45/50, Loss: 4.0981009078677744e-05\n",
      "Epoch 46/50, Loss: 3.400559216970578e-05\n",
      "Epoch 47/50, Loss: 3.2827287213876843e-05\n",
      "Epoch 48/50, Loss: 2.9390175768639892e-05\n",
      "Epoch 49/50, Loss: 3.0960240110289305e-05\n",
      "Epoch 50/50, Loss: 2.669324203452561e-05\n",
      "\n",
      "Training model with sklearn features\n",
      "Epoch 1/50, Loss: 0.6642056107521057\n",
      "Epoch 2/50, Loss: 0.3708759546279907\n",
      "Epoch 3/50, Loss: 0.10226582735776901\n",
      "Epoch 4/50, Loss: 0.0112235639244318\n",
      "Epoch 5/50, Loss: 0.006691723130643368\n",
      "Epoch 6/50, Loss: 0.003309001214802265\n",
      "Epoch 7/50, Loss: 0.0023017185740172863\n",
      "Epoch 8/50, Loss: 0.001242110156454146\n",
      "Epoch 9/50, Loss: 0.0005389135330915451\n",
      "Epoch 10/50, Loss: 0.00033837513183243573\n",
      "Epoch 11/50, Loss: 0.00022908678511157632\n",
      "Epoch 12/50, Loss: 0.00017325572844129056\n",
      "Epoch 13/50, Loss: 0.00010639224637998268\n",
      "Epoch 14/50, Loss: 9.55228679231368e-05\n",
      "Epoch 15/50, Loss: 7.991251914063469e-05\n",
      "Epoch 16/50, Loss: 4.8830195737536997e-05\n",
      "Epoch 17/50, Loss: 3.4020344173768535e-05\n",
      "Epoch 18/50, Loss: 3.234754694858566e-05\n",
      "Epoch 19/50, Loss: 3.344540164107457e-05\n",
      "Epoch 20/50, Loss: 2.4384091375395656e-05\n",
      "Epoch 21/50, Loss: 2.3079515813151374e-05\n",
      "Epoch 22/50, Loss: 2.0577967006829567e-05\n",
      "Epoch 23/50, Loss: 1.451667685614666e-05\n",
      "Epoch 24/50, Loss: 2.170298103010282e-05\n",
      "Epoch 25/50, Loss: 9.227519512933213e-06\n",
      "Epoch 26/50, Loss: 1.5203746443148702e-05\n",
      "Epoch 27/50, Loss: 1.4113315046415664e-05\n",
      "Epoch 28/50, Loss: 1.0207495506620035e-05\n",
      "Epoch 29/50, Loss: 1.144803627539659e-05\n",
      "Epoch 30/50, Loss: 8.326198440045118e-06\n",
      "Epoch 31/50, Loss: 6.110441972850822e-06\n",
      "Epoch 32/50, Loss: 8.664334018249065e-06\n",
      "Epoch 33/50, Loss: 8.524360055162106e-06\n",
      "Epoch 34/50, Loss: 6.095698154240381e-06\n",
      "Epoch 35/50, Loss: 7.4489489634288475e-06\n",
      "Epoch 36/50, Loss: 5.3024305088911206e-06\n",
      "Epoch 37/50, Loss: 3.67833945347229e-06\n",
      "Epoch 38/50, Loss: 4.203016942483373e-06\n",
      "Epoch 39/50, Loss: 6.45815589450649e-06\n",
      "Epoch 40/50, Loss: 3.92116817238275e-06\n",
      "Epoch 41/50, Loss: 4.483747034100816e-06\n",
      "Epoch 42/50, Loss: 4.22019547841046e-06\n",
      "Epoch 43/50, Loss: 2.2900308067619335e-06\n",
      "Epoch 44/50, Loss: 3.5850052881869487e-06\n",
      "Epoch 45/50, Loss: 3.2855723475222476e-06\n",
      "Epoch 46/50, Loss: 2.522699787732563e-06\n",
      "Epoch 47/50, Loss: 3.1716813282400835e-06\n",
      "Epoch 48/50, Loss: 3.2757884582679253e-06\n",
      "Epoch 49/50, Loss: 3.874184130836511e-06\n",
      "Epoch 50/50, Loss: 3.0766800591663923e-06\n"
     ]
    }
   ],
   "source": [
    "# Train the model for 50 epochs on both custom and sklearn vectors\n",
    "\n",
    "# Function for training and evaluating the model\n",
    "def train(X_train, y_train):\n",
    "    X_train_torch = torch.tensor(X_train).float().to(device)\n",
    "    y_train_torch = torch.tensor(y_train).float().to(device)\n",
    "\n",
    "    # Create a DataLoader for the training data\n",
    "    train_data = TensorDataset(X_train_torch, y_train_torch)\n",
    "    train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "\n",
    "    # Create a feedforward neural network model\n",
    "    # you may use any activation function on the hidden layers\n",
    "    # you should use binary cross-entropy as your loss function\n",
    "    # Adam is an appropriate optimizer for this task\n",
    "    model = feedforward().to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch+1}/50, Loss: {loss.item()}')\n",
    "\n",
    "    return model\n",
    "\n",
    "print(\"Training model with custom features\")\n",
    "custom_model = train(X_train_custom, y_train)\n",
    "\n",
    "print(\"\\nTraining model with sklearn features\")\n",
    "sklearn_model = train(X_train_sklearn.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdf1319f-41c0-4237-982f-b60d492fbbd7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdf1319f-41c0-4237-982f-b60d492fbbd7",
    "outputId": "187d0ec2-1f99-417e-b23d-de234adb2848"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom TF-IDF Model:\n",
      "Accuracy: 0.7850000262260437\n",
      "AUROC: 0.8937392882347011\n",
      "F1 Score: 0.7962085604667664\n",
      "\n",
      "Sklearn TfidfVectorizer Model:\n",
      "Accuracy: 0.8100000023841858\n",
      "AUROC: 0.8970662365157778\n",
      "F1 Score: 0.8155339360237122\n"
     ]
    }
   ],
   "source": [
    "# !pip install torcheval\n",
    "\n",
    "# Evaluate the model using custom and sklearn vectors\n",
    "# Test the model using custom and sklearn vectors\n",
    "# Evaluate the model and report the score using Binary F1 score, Binary AUROC and Binary accuracy\n",
    "\n",
    "from torcheval.metrics import BinaryAccuracy, BinaryAUROC, BinaryF1Score\n",
    "\n",
    "accuracy_metric = BinaryAccuracy()\n",
    "auroc_metric = BinaryAUROC()\n",
    "f1_metric = BinaryF1Score()\n",
    "\n",
    "# Function for evaluating the model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    X_test_torch = torch.tensor(X_test).float().to(device)\n",
    "    y_test_torch = torch.tensor(y_test).float().to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test_torch).squeeze()\n",
    "\n",
    "    # Update metric calculations\n",
    "    accuracy_metric.update(outputs, y_test_torch)\n",
    "    auroc_metric.update(outputs, y_test_torch)\n",
    "    f1_metric.update(outputs, y_test_torch)\n",
    "\n",
    "    # Compute final metrics\n",
    "    final_accuracy = accuracy_metric.compute()\n",
    "    final_auroc = auroc_metric.compute()\n",
    "    final_f1 = f1_metric.compute()\n",
    "\n",
    "    accuracy_metric.reset()\n",
    "    auroc_metric.reset()\n",
    "    f1_metric.reset()\n",
    "\n",
    "    return final_accuracy.item(), final_auroc.item(), final_f1.item()\n",
    "\n",
    "custom_accuracy, custom_auroc, custom_f1 = evaluate_model(custom_model, X_test_custom, y_test)\n",
    "sklearn_accuracy, sklearn_auroc, sklearn_f1 = evaluate_model(sklearn_model, X_test_sklearn.toarray(), y_test)\n",
    "\n",
    "print(\"Custom TF-IDF Model:\")\n",
    "print(\"Accuracy:\", custom_accuracy)\n",
    "print(\"AUROC:\", custom_auroc)\n",
    "print(\"F1 Score:\", custom_f1)\n",
    "\n",
    "print(\"\\nSklearn TfidfVectorizer Model:\")\n",
    "print(\"Accuracy:\", sklearn_accuracy)\n",
    "print(\"AUROC:\", sklearn_auroc)\n",
    "print(\"F1 Score:\", sklearn_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a332b6",
   "metadata": {},
   "source": [
    "NOTE: As in the last task, we're expecting to see a F1 score of over 60% using both your custom features and the sklearn features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b269ee9",
   "metadata": {
    "id": "8b269ee9"
   },
   "source": [
    "5 points in this assignment are reserved for overall style (both for writing and for code submitted). All work submitted should be clear, easily interpretable, and checked for spelling, etc. (Re-read what you write and make sure it makes sense). Course staff are always happy to give grammatical help (but we won't pre-grade the content of your answers)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
