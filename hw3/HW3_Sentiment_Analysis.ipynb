{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e28f7c45-f3f5-45b8-8b41-5012bc57d4bd",
   "metadata": {
    "id": "e28f7c45-f3f5-45b8-8b41-5012bc57d4bd"
   },
   "source": [
    "Homework 3: Sentiment Analysis\n",
    "----\n",
    "\n",
    "The following instructions apply to all notebooks and `.py` files you submit for this homework.\n",
    "\n",
    "Due date: April 15th, 2024 11:59 PM (EST)\n",
    "\n",
    "Total Points: (105)\n",
    "- Task 0: 05 points\n",
    "- Task 1: 10 points\n",
    "- Task 2: 20 points\n",
    "- Task 3: 25 points\n",
    "- Task 4: 40 points (question in LSTM_EncDec.ipynb)\n",
    "\n",
    "Goals:\n",
    "- understand the difficulties of counting and probabilities in NLP applications\n",
    "- work with real world data using different approaches to classification\n",
    "- stress test your model (to some extent)\n",
    "\n",
    "\n",
    "Allowed python modules:\n",
    "- `numpy`, `matplotlib`, `keras`, `pytorch`, `nltk`, `pandas`, `sci-kit learn` (`sklearn`), `seaborn`, and all built-in python libraries (e.g. `math` and `string`)\n",
    "- if you would like to use a library not on this list, please check with us on Campuswire first.\n",
    "- all *necessary* imports have been included for you (all imports that we used in our solution)\n",
    "\n",
    "Instructions:\n",
    "- Complete outlined problems in this notebook.\n",
    "- When you have finished, __clear the kernel__ and __run__ your notebook \"fresh\" from top to bottom. Ensure that there are __no errors__.\n",
    "    - If a problem asks for you to write code that does result in an error (as in, the answer to the problem is an error), leave the code in your notebook but commented out so that running from top to bottom does not result in any errors.\n",
    "- Double check that you have completed Task 0.\n",
    "- Submit your work on Gradescope.\n",
    "- Double check that your submission on Gradescope looks like you believe it should."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc3f1aa-6b6e-4953-a30d-a79ab0794170",
   "metadata": {
    "id": "cfc3f1aa-6b6e-4953-a30d-a79ab0794170"
   },
   "source": [
    "Names & Sections\n",
    "----\n",
    "Names: __YOUR NAMES HERE__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4307e0-20b7-4ed3-9fa0-086f899b4583",
   "metadata": {
    "id": "2a4307e0-20b7-4ed3-9fa0-086f899b4583"
   },
   "source": [
    "Task 0: Name, References, Reflection (5 points)\n",
    "---\n",
    "\n",
    "References\n",
    "---\n",
    "List the resources you consulted to complete this homework here. Write one sentence per resource about what it provided to you. If you consulted no references to complete your assignment, write a brief sentence stating that this is the case and why it was the case for you.\n",
    "\n",
    "(Example)\n",
    "- https://docs.python.org/3/tutorial/datastructures.html\n",
    "    - Read about the the basics and syntax for data structures in python.\n",
    "\n",
    "AI Collaboration\n",
    "---\n",
    "Following the *Policy on the use of Generative AI* in the syllabus, please cite any LLMs that you used here and briefly describe what you used them for, including to improve language clarity in the written sections.\n",
    "\n",
    "Reflection\n",
    "----\n",
    "Answer the following questions __after__ you complete this assignment (no more than 1 sentence per question required, this section is graded on completion):\n",
    "\n",
    "1. Does this work reflect your best effort?\n",
    "2. What was/were the most challenging part(s) of the assignment?\n",
    "3. If you want feedback, what function(s) or problem(s) would you like feedback on and why?\n",
    "4. Briefly reflect on how your partnership functioned--who did which tasks, how was the workload on each of you individually as compared to the previous homeworks, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669c4773-456b-4d5a-bdce-df7bbcb3d16b",
   "metadata": {
    "id": "669c4773-456b-4d5a-bdce-df7bbcb3d16b"
   },
   "source": [
    "Task 1: Provided Data Write-Up (10 points)\n",
    "---\n",
    "\n",
    "Every time you use a data set in an NLP application (or in any software application), you should be able to answer a set of questions about that data. Answer these now. Default to no more than 1 sentence per question needed. If more explanation is necessary, do give it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c281567d-b99b-45df-8b1b-2b0e35cb9196",
   "metadata": {
    "id": "c281567d-b99b-45df-8b1b-2b0e35cb9196"
   },
   "source": [
    "This is about the __provided__ movie review data set.\n",
    "\n",
    "1. Where did you get the data from? The provided dataset(s) were sub-sampled from https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
    "2. (1 pt) How was the data collected (where did the people acquiring the data get it from and how)?\n",
    "3. (2 pts) How large is the dataset (answer for both the train and the dev set, separately)? (# reviews, # tokens in both the train and dev sets)\n",
    "4. (1 pt) What is your data? (i.e. newswire, tweets, books, blogs, etc)\n",
    "5. (1 pt) Who produced the data? (who were the authors of the text? Your answer might be a specific person or a particular group of people)\n",
    "6. (2 pts) What is the distribution of labels in the data (answer for both the train and the dev set, separately)?\n",
    "7. (2 pts) How large is the vocabulary (answer for both the train and the dev set, separately)?\n",
    "8. (1 pt) How big is the overlap between the vocabulary for the train and dev set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d64fd8f-f130-4f1b-8624-c151c502344b",
   "metadata": {
    "id": "2d64fd8f-f130-4f1b-8624-c151c502344b"
   },
   "source": [
    "Task 2: Train a Logistic Regression Model (20 points)\n",
    "----\n",
    "1. Implement a custom function to read in a dataset, and return a list of tuples, using the Tf-Idf feature extraction technique.\n",
    "2. Compare your implementation to `sklearn`'s TfidfVectorizer (imported below) by timing both on the provided datasets using the time module.\n",
    "3. Using each set of features, and `sklearn`'s implementation of `LogisticRegression`, train a machine learning model to predict sentiment on the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e9bbb93-9a5d-4326-8dd0-d2ffcf242123",
   "metadata": {
    "id": "0e9bbb93-9a5d-4326-8dd0-d2ffcf242123"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "import time\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c515ae-3637-42b6-9412-e0710e7821bb",
   "metadata": {
    "id": "62c515ae-3637-42b6-9412-e0710e7821bb"
   },
   "outputs": [],
   "source": [
    "# The following function reads a data-file and splits the contents by tabs.\n",
    "# The first column is an ID, and thus is discarded. The second column consists of the actual reviews data.\n",
    "# The third column is the true label for each data point.\n",
    "\n",
    "# The function returns two objects - a list of all reviews, and a numpy array of labels.\n",
    "# You will need to use this function later.\n",
    "\n",
    "def get_lists(input_file):\n",
    "    f=open(input_file, 'r')\n",
    "    lines = [line.split('\\t')[1:] for line in f.readlines()]\n",
    "    X = [row[0] for row in lines]\n",
    "    y=np.array([int(row[1]) for row in lines])\n",
    "    return X, y\n",
    "\n",
    "# Fill in the following function to take a corpus (list of reviews) as input,\n",
    "# extract TfIdf values and return an array of features and the vocabulary.\n",
    "\n",
    "# If the vocabulary argument is supplied, then the function should only convert the input corpus\n",
    "# to feature vectors using the provided vocabulary and the max_features argument (if not None).\n",
    "# In this case, the function should return feature vectors and the supplied vocabulary.\n",
    "\n",
    "# If the max_features parameter is set to None, then all words in the corpus should be used.\n",
    "# If the max_features parameter is specified (say, k),\n",
    "# then only use the k most frequent words in the corpus to build your vocabulary.\n",
    "\n",
    "# The function should return two things.\n",
    "\n",
    "# The first object should be a numpy array of shape (n_documents, vocab_size),\n",
    "# which contains the TF-IDF feature vectors for each document.\n",
    "\n",
    "# The second object should be a dictionary of the words in the vocabulary,\n",
    "# mapped to their corresponding index in alphabetical sorted order.\n",
    "\n",
    "def get_tfidf_vectors(token_lists, max_features=None, vocabulary=None):\n",
    "\n",
    "    #YOUR CODE HERE\n",
    "\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62226f12-d0e5-4e74-887e-5cd852b96707",
   "metadata": {
    "id": "62226f12-d0e5-4e74-887e-5cd852b96707"
   },
   "source": [
    "We will now compare the runtime of our Tf-Idf implementation to the `sklearn` implementation. Call the respective functions with appropriate arguments in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2e6c726-0e12-4e1f-8c8b-146a9a506a3f",
   "metadata": {
    "id": "e2e6c726-0e12-4e1f-8c8b-146a9a506a3f"
   },
   "outputs": [],
   "source": [
    "# define constants for the files we are using\n",
    "TRAIN_FILE = \"movie_reviews_train.txt\"\n",
    "TEST_FILE = \"movie_reviews_test.txt\"\n",
    "\n",
    "train_corpus, y_train = get_lists(TRAIN_FILE)\n",
    "\n",
    "# First we will use our custom vectorizer to convert words to features, and time it.\n",
    "\n",
    "###### YOUR CODE HERE #######\n",
    "\n",
    "# print(\"Time taken: \", end-start, \" seconds\")\n",
    "\n",
    "# Next we will use sklearn's TfidfVectorizer to load in the data, and time it.\n",
    "\n",
    "###### YOUR CODE HERE #######\n",
    "\n",
    "\n",
    "# print(\"Time taken: \", end-start, \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35afb9c6",
   "metadata": {},
   "source": [
    "NOTE: Ideally, your vectorizer should be within one order of magnitude of the sklearn implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bdbf31c-bf6b-4ab4-b87b-47dd7c5468a8",
   "metadata": {
    "id": "8bdbf31c-bf6b-4ab4-b87b-47dd7c5468a8"
   },
   "outputs": [],
   "source": [
    "# Any additional code needed to answer questions below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6463f022-7433-4397-88ed-eed8b01b1a45",
   "metadata": {
    "id": "6463f022-7433-4397-88ed-eed8b01b1a45"
   },
   "source": [
    "1. How large is the vocabulary generated by your vectorizer?<br> **YOUR ANSWER HERE**\n",
    "2. How large is the vocabulary generated by the `sklearn` TfidfVectorizer?<br> **YOUR ANSWER HERE**\n",
    "3. Where might these differences be coming from?<br> **YOUR ANSWER HERE**\n",
    "4. What steps did you take to ensure your vectorizer is optimized for best possible runtime?<br> **YOUR ANSWER HERE**\n",
    "5. How sparse are your custom features (average percentage of features per review that are zero)?<br> **YOUR ANSWER HERE**\n",
    "6. How sparse are the TfidfVectorizer's features?<br> **YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38f496b",
   "metadata": {},
   "source": [
    "NOTE: if you set the lowercase option to False, the sklearn vectorizer should have a vocabulary of around 50k words/tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c76612-4dd4-489c-90e4-0c38029c32d1",
   "metadata": {
    "id": "09c76612-4dd4-489c-90e4-0c38029c32d1"
   },
   "source": [
    "**Logistic Regression**\n",
    "\n",
    "Now, we will compare how our custom features stack up against sklearn's TfidfVectorizer, by training two separate Logistic Regression classifiers - one on each set of feature vectors. Then load the test set, and convert it to two sets of feature vectors, one using our custom vectorizer (to do this, provide the vocabulary as a function argument), and one using sklearn's Tfidf (use the same object as before to transform the test inputs). For both classifiers, print the average accuracy on the test set and the F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68eb6d36-1e71-4665-aab4-1217a42e6dcc",
   "metadata": {
    "id": "68eb6d36-1e71-4665-aab4-1217a42e6dcc"
   },
   "outputs": [],
   "source": [
    "# First use sklearn's LogisticRegression classifier to do sentiment analysis using your custom feature vectors:\n",
    "\n",
    "###### YOUR CODE HERE #######\n",
    "\n",
    "# Load the test data, extract features using your custom vectorizer, and test the performance of the LR classifier\n",
    "\n",
    "###### YOUR CODE HERE #######\n",
    "\n",
    "# Print the accuracy of your model on the test data\n",
    "\n",
    "###### YOUR CODE HERE #######\n",
    "\n",
    "# Now repeat the above steps, but this time using features extracted by sklearn's Tfidfvectorizer\n",
    "\n",
    "###### YOUR CODE HERE #######\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5679888",
   "metadata": {},
   "source": [
    "NOTE: we're expecting to see a F1 score of around 80% using both your custom features and the sklearn features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0220a93-ba22-411a-962f-983ffe3a34f2",
   "metadata": {
    "id": "f0220a93-ba22-411a-962f-983ffe3a34f2"
   },
   "source": [
    "Finally, repeat the process (training and testing), but this time, set the max_features argument to 1000 for both our custom vectorizer and sklearn's Tfidfvectorizer. Report average accuracy and F1 scores for both classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f995a09c-0447-422d-8b37-e9120cfadfab",
   "metadata": {
    "id": "f995a09c-0447-422d-8b37-e9120cfadfab"
   },
   "outputs": [],
   "source": [
    "###### YOUR CODE HERE #######\n",
    "\n",
    "# First use sklearn's LogisticRegression classifier to do sentiment analysis using your custom feature vectors:\n",
    "\n",
    "###### YOUR CODE HERE #######\n",
    "\n",
    "\n",
    "# Load the test data, extract features using your custom vectorizer, and test the performance of the LR classifier\n",
    "\n",
    "###### YOUR CODE HERE #######\n",
    "\n",
    "\n",
    "# Print the accuracy of your model on the test data\n",
    "\n",
    "###### YOUR CODE HERE #######\n",
    "\n",
    "# Now repeat the above steps, but this time using features extracted by sklearn's Tfidfvectorizer\n",
    "\n",
    "###### YOUR CODE HERE #######\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2858e409-8a87-43aa-8646-1e5419cce6db",
   "metadata": {
    "id": "2858e409-8a87-43aa-8646-1e5419cce6db"
   },
   "source": [
    "1. Is there a stark difference between the two vectorizers with 1000 features?<br>**YOUR ANSWER HERE**\n",
    "2. Use sklearn's documentation for the Tfidfvectorizer to figure out what may be causing the performance difference (or lack thereof).<br>**YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68df8d77",
   "metadata": {},
   "source": [
    "NOTE: Irrespective of your conclusions, both implementations should be above 60% F1 Score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c652f8ab-3893-4021-b33f-c466b2e1d98a",
   "metadata": {
    "id": "c652f8ab-3893-4021-b33f-c466b2e1d98a"
   },
   "source": [
    "Task 3: Train a Feedforward Neural Network Model (25 points)\n",
    "----\n",
    "1. Using PyTorch, implement a feedforward neural network to do sentiment analysis. This model should take sparse vectors of length 10000 as input (note this is 10000, not 1000), and have a single output with the sigmoid activation function. The number of hidden layers, and intermediate activation choices are up to you, but please make sure your model does not take more than ~1 minute to train.\n",
    "2. Evaluate the model using PyTorch functions for average accuracy, area under the ROC curve and F1 scores (see [torcheval](https://pytorch.org/torcheval/stable/)) using both vectorizers, with max_features set to 10000 in both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f563ec2-d02a-4176-908c-011acd8851de",
   "metadata": {
    "id": "3f563ec2-d02a-4176-908c-011acd8851de"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# if torch.backends.mps.is_available():\n",
    "# \tdevice = torch.device(\"mps\")\n",
    "if torch.cuda.is_available():\n",
    "\tdevice = torch.device(\"cuda\")\n",
    "else:\n",
    "\tdevice = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcb6aa45-e33a-4d08-bff8-996e1f80dad2",
   "metadata": {
    "id": "fcb6aa45-e33a-4d08-bff8-996e1f80dad2"
   },
   "outputs": [],
   "source": [
    "class feedforward(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        ###### YOUR CODE HERE #######\n",
    "\n",
    "    def forward(self, X):\n",
    "        ###### YOUR CODE HERE #######\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        ###### YOUR CODE HERE #######\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba08e134-2a81-48b9-89c3-43046be4cc1b",
   "metadata": {
    "id": "ba08e134-2a81-48b9-89c3-43046be4cc1b"
   },
   "outputs": [],
   "source": [
    "# Load the data using custom and sklearn vectors\n",
    "\n",
    "###### YOUR CODE HERE #######\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "055e1e59-4d96-4a6b-8e16-cd14fcc4b760",
   "metadata": {
    "id": "055e1e59-4d96-4a6b-8e16-cd14fcc4b760"
   },
   "outputs": [],
   "source": [
    "# Create a feedforward neural network model\n",
    "# you may use any activation function on the hidden layers\n",
    "# you should use binary cross-entropy as your loss function\n",
    "# Adam is an appropriate optimizer for this task\n",
    "\n",
    "\n",
    "###### YOUR CODE HERE #######\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "237cbc15-3473-427d-8d3f-af1059f736b4",
   "metadata": {
    "id": "237cbc15-3473-427d-8d3f-af1059f736b4"
   },
   "outputs": [],
   "source": [
    "# Train the model for 50 epochs on both custom and sklearn vectors\n",
    "\n",
    "\n",
    "###### YOUR CODE HERE #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdf1319f-41c0-4237-982f-b60d492fbbd7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdf1319f-41c0-4237-982f-b60d492fbbd7",
    "outputId": "187d0ec2-1f99-417e-b23d-de234adb2848"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torcheval\n",
      "  Downloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/179.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/179.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.10.0)\n",
      "Installing collected packages: torcheval\n",
      "Successfully installed torcheval-0.0.7\n"
     ]
    }
   ],
   "source": [
    "!pip install torcheval\n",
    "\n",
    "# Evaluate the model using custom and sklearn vectors\n",
    "\n",
    "###### YOUR CODE HERE #######\n",
    "\n",
    "\n",
    "from torcheval.metrics.functional import binary_f1_score\n",
    "from torcheval.metrics import BinaryAUROC, BinaryAccuracy\n",
    "\n",
    "# Test the model using custom and sklearn vectors\n",
    "# Evaluate the model and report the score using Binary F1 score, Binary AUROC and Binary accuracy\n",
    "\n",
    "###### YOUR CODE HERE #######\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a332b6",
   "metadata": {},
   "source": [
    "NOTE: As in the last task, we're expecting to see a F1 score of over 60% using both your custom features and the sklearn features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b269ee9",
   "metadata": {
    "id": "8b269ee9"
   },
   "source": [
    "5 points in this assignment are reserved for overall style (both for writing and for code submitted). All work submitted should be clear, easily interpretable, and checked for spelling, etc. (Re-read what you write and make sure it makes sense). Course staff are always happy to give grammatical help (but we won't pre-grade the content of your answers)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
