{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e28f7c45-f3f5-45b8-8b41-5012bc57d4bd",
   "metadata": {
    "id": "e28f7c45-f3f5-45b8-8b41-5012bc57d4bd"
   },
   "source": [
    "Homework 3: Sentiment Analysis\n",
    "----\n",
    "\n",
    "The following instructions apply to all notebooks and `.py` files you submit for this homework.\n",
    "\n",
    "Due date: April 15th, 2024 11:59 PM (EST)\n",
    "\n",
    "Total Points: (105)\n",
    "- Task 0: 05 points\n",
    "- Task 1: 10 points\n",
    "- Task 2: 20 points\n",
    "- Task 3: 25 points\n",
    "- Task 4: 40 points (question in LSTM_EncDec.ipynb)\n",
    "\n",
    "Goals:\n",
    "- understand the difficulties of counting and probabilities in NLP applications\n",
    "- work with real world data using different approaches to classification\n",
    "- stress test your model (to some extent)\n",
    "\n",
    "\n",
    "Allowed python modules:\n",
    "- `numpy`, `matplotlib`, `keras`, `pytorch`, `nltk`, `pandas`, `sci-kit learn` (`sklearn`), `seaborn`, and all built-in python libraries (e.g. `math` and `string`)\n",
    "- if you would like to use a library not on this list, please check with us on Campuswire first.\n",
    "- all *necessary* imports have been included for you (all imports that we used in our solution)\n",
    "\n",
    "Instructions:\n",
    "- Complete outlined problems in this notebook.\n",
    "- When you have finished, __clear the kernel__ and __run__ your notebook \"fresh\" from top to bottom. Ensure that there are __no errors__.\n",
    "    - If a problem asks for you to write code that does result in an error (as in, the answer to the problem is an error), leave the code in your notebook but commented out so that running from top to bottom does not result in any errors.\n",
    "- Double check that you have completed Task 0.\n",
    "- Submit your work on Gradescope.\n",
    "- Double check that your submission on Gradescope looks like you believe it should."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc3f1aa-6b6e-4953-a30d-a79ab0794170",
   "metadata": {
    "id": "cfc3f1aa-6b6e-4953-a30d-a79ab0794170"
   },
   "source": [
    "Names & Sections\n",
    "----\n",
    "Names: __Sudarshan Paranjape__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4307e0-20b7-4ed3-9fa0-086f899b4583",
   "metadata": {
    "id": "2a4307e0-20b7-4ed3-9fa0-086f899b4583"
   },
   "source": [
    "Task 0: Name, References, Reflection (5 points)\n",
    "---\n",
    "\n",
    "References\n",
    "---\n",
    "List the resources you consulted to complete this homework here. Write one sentence per resource about what it provided to you. If you consulted no references to complete your assignment, write a brief sentence stating that this is the case and why it was the case for you.\n",
    "\n",
    "(Example)\n",
    "- https://docs.python.org/3/tutorial/datastructures.html\n",
    "    - Read about the the basics and syntax for data structures in python.\n",
    "\n",
    "AI Collaboration\n",
    "---\n",
    "Following the *Policy on the use of Generative AI* in the syllabus, please cite any LLMs that you used here and briefly describe what you used them for, including to improve language clarity in the written sections.\n",
    "\n",
    "Reflection\n",
    "----\n",
    "Answer the following questions __after__ you complete this assignment (no more than 1 sentence per question required, this section is graded on completion):\n",
    "\n",
    "1. Does this work reflect your best effort? -- yes\n",
    "2. What was/were the most challenging part(s) of the assignment? -- Finetuning the TFIDF and FFNN\n",
    "3. If you want feedback, what function(s) or problem(s) would you like feedback on and why?\n",
    "4. Briefly reflect on how your partnership functioned--who did which tasks, how was the workload on each of you individually as compared to the previous homeworks, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669c4773-456b-4d5a-bdce-df7bbcb3d16b",
   "metadata": {
    "id": "669c4773-456b-4d5a-bdce-df7bbcb3d16b"
   },
   "source": [
    "Task 1: Provided Data Write-Up (10 points)\n",
    "---\n",
    "\n",
    "Every time you use a data set in an NLP application (or in any software application), you should be able to answer a set of questions about that data. Answer these now. Default to no more than 1 sentence per question needed. If more explanation is necessary, do give it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c281567d-b99b-45df-8b1b-2b0e35cb9196",
   "metadata": {
    "id": "c281567d-b99b-45df-8b1b-2b0e35cb9196"
   },
   "source": [
    "This is about the __provided__ movie review data set.\n",
    "\n",
    "1. Where did you get the data from? The provided dataset(s) were sub-sampled from https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
    "2. (1 pt) How was the data collected (where did the people acquiring the data get it from and how)? -- Data was collected by scraping the IMDB website<br>\n",
    "\n",
    "3. (2 pts) How large is the dataset (answer for both the train and the dev set, separately)? (# reviews, # tokens in both the train and dev sets) -- Train dataset has 1600 reviews and ~22000 tokens. Test dataset has 200 reviews and similar no. of tokens.<br>\n",
    "<br>\n",
    "\n",
    "4. (1 pt) What is your data? (i.e. newswire, tweets, books, blogs, etc) -- the data is 50K movie reviews having 25,000 highly polar movie reviews for training and 25,000 for testing<br>\n",
    "<br>\n",
    "5. (1 pt) Who produced the data? (who were the authors of the text? Your answer might be a specific person or a particular group of people) -- The data has been created by Stanford University<br>\n",
    "<br>\n",
    "6. (2 pts) What is the distribution of labels in the data (answer for both the train and the dev set, separately)? -- for the training set nos 1 = 804, 0 = 796<br>for testing set nos 1 = 109, 0 = 91\n",
    "<br>\n",
    "7. (2 pts) How large is the vocabulary (answer for both the train and the dev set, separately)? train_set = 30705, dev_set = 8953\n",
    "\n",
    "\n",
    "8. (1 pt) How big is the overlap between the vocabulary for the train and dev set? -- 6574"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ae165d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in train data: 425345\n",
      "Number of tokens in dev data: 54599\n",
      "Number of vocab in train data: 30705\n",
      "Number of vocab in dev data: 8953\n",
      "Overlap between train and dev vocab: 6574\n"
     ]
    }
   ],
   "source": [
    "train_data_file = 'movie_reviews_train.txt'\n",
    "train_df = pd.read_csv(train_data_file, sep='\\t', header=None, names=['id', 'review', 'label'])[['review', 'label']]\n",
    "X_train, y_train = train_df['review'].values, train_df['label'].values\n",
    "\n",
    "dev_data_file = 'movie_reviews_dev.txt'\n",
    "dev_df = pd.read_csv(dev_data_file, sep='\\t', header=None, names=['id', 'review', 'label'])[['review', 'label']]\n",
    "X_dev, y_dev = dev_df['review'].values, dev_df['label'].values\n",
    "\n",
    "test_data_file = 'movie_reviews_test.txt'\n",
    "test_df = pd.read_csv(test_data_file, sep='\\t', header=None, names=['id', 'review', 'label'])[['review', 'label']]\n",
    "X_test, y_test = test_df['review'].values, test_df['label'].values\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "def num_tokens(data):\n",
    "    vocab = set()\n",
    "    num_tokens = 0\n",
    "    for doc in data:\n",
    "        tokens = word_tokenize(doc)\n",
    "        num_tokens += len(tokens)\n",
    "        vocab.update(tokens)\n",
    "    return num_tokens, len(vocab), vocab\n",
    "\n",
    "train_num_tokens, train_num_vocab, train_vocab = num_tokens(X_train)\n",
    "dev_num_tokens, dev_num_vocab, dev_vocab = num_tokens(X_dev)\n",
    "print('Number of tokens in train data:', train_num_tokens)\n",
    "print('Number of tokens in dev data:', dev_num_tokens)\n",
    "print('Number of vocab in train data:', train_num_vocab)\n",
    "print('Number of vocab in dev data:', dev_num_vocab)\n",
    "\n",
    "print('Overlap between train and dev vocab:', len(train_vocab & dev_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d64fd8f-f130-4f1b-8624-c151c502344b",
   "metadata": {
    "id": "2d64fd8f-f130-4f1b-8624-c151c502344b"
   },
   "source": [
    "Task 2: Train a Logistic Regression Model (20 points)\n",
    "----\n",
    "1. Implement a custom function to read in a dataset, and return a list of tuples, using the Tf-Idf feature extraction technique.\n",
    "2. Compare your implementation to `sklearn`'s TfidfVectorizer (imported below) by timing both on the provided datasets using the time module.\n",
    "3. Using each set of features, and `sklearn`'s implementation of `LogisticRegression`, train a machine learning model to predict sentiment on the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e9bbb93-9a5d-4326-8dd0-d2ffcf242123",
   "metadata": {
    "id": "0e9bbb93-9a5d-4326-8dd0-d2ffcf242123"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "import time\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62c515ae-3637-42b6-9412-e0710e7821bb",
   "metadata": {
    "id": "62c515ae-3637-42b6-9412-e0710e7821bb"
   },
   "outputs": [],
   "source": [
    "from re import U\n",
    "# The following function reads a data-file and splits the contents by tabs.\n",
    "# The first column is an ID, and thus is discarded. The second column consists of the actual reviews data.\n",
    "# The third column is the true label for each data point.\n",
    "\n",
    "# The function returns two objects - a list of all reviews, and a numpy array of labels.\n",
    "# You will need to use this function later.\n",
    "\n",
    "def get_lists(input_file):\n",
    "    f=open(input_file, 'r')\n",
    "    lines = [line.split('\\t')[1:] for line in f.readlines()]\n",
    "    X = [row[0] for row in lines]\n",
    "    y=np.array([int(row[1]) for row in lines])\n",
    "    return X, y\n",
    "\n",
    "# Fill in the following function to take a corpus (list of reviews) as input,\n",
    "# extract TfIdf values and return an array of features and the vocabulary.\n",
    "\n",
    "# If the vocabulary argument is supplied, then the function should only convert the input corpus\n",
    "# to feature vectors using the provided vocabulary and the max_features argument (if not None).\n",
    "# In this case, the function should return feature vectors and the supplied vocabulary.\n",
    "\n",
    "# If the max_features parameter is set to None, then all words in the corpus should be used.\n",
    "# If the max_features parameter is specified (say, k),\n",
    "# then only use the k most frequent words in the corpus to build your vocabulary.\n",
    "\n",
    "# The function should return two things.\n",
    "\n",
    "# The first object should be a numpy array of shape (n_documents, vocab_size),\n",
    "# which contains the TF-IDF feature vectors for each document.\n",
    "\n",
    "# The second object should be a dictionary of the words in the vocabulary,\n",
    "# mapped to their corresponding index in alphabetical sorted order.\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def count_word_occurrences(corpus):\n",
    "    all_words = []\n",
    "    for doc in corpus:\n",
    "        words = word_tokenize(doc.lower())\n",
    "        all_words.extend(words)\n",
    "    word_counts = Counter(all_words)\n",
    "    # Remove stopwords and non-alphabetic tokens\n",
    "    word_list = [word for word in word_counts if word.isalpha() and word not in stopwords]\n",
    "    return word_list\n",
    "\n",
    "def tf_mtx(corpus, unique_words):\n",
    "    tf_matrix = []\n",
    "    for doc in corpus:\n",
    "        doc_tokens = word_tokenize(doc.lower())\n",
    "        token_freq = Counter(doc_tokens)\n",
    "        doc_tf = [token_freq[word] / len(doc_tokens) for word in unique_words]\n",
    "        tf_matrix.append(doc_tf)\n",
    "    return np.array(tf_matrix)\n",
    "\n",
    "\n",
    "def idf_mtx(corpus, unique_words, smoothing=1):\n",
    "    total_docs = len(corpus)\n",
    "    doc_freq = np.array([sum(1 for doc in corpus if word in doc.split()) for word in unique_words])\n",
    "    idf_values = np.log((total_docs + smoothing) / (1 + doc_freq))\n",
    "    idf_dict = dict(zip(unique_words, idf_values))\n",
    "    return idf_dict\n",
    "\n",
    "\n",
    "def tf_idf(corpus, unique_words, smoothing=1):\n",
    "    tf_matrix = tf_mtx(corpus, unique_words)\n",
    "    idf_dict = idf_mtx(corpus, unique_words, smoothing)\n",
    "    idf_vector = np.array([idf_dict[word] for word in unique_words])\n",
    "    \n",
    "    # Element-wise multiplication of TF matrix with IDF vector\n",
    "    tf_idf_matrix = tf_matrix * idf_vector\n",
    "    return tf_idf_matrix\n",
    "\n",
    "def get_tfidf_vectors(token_lists, max_features=None, vocabulary=None,smoothing = 1):\n",
    "    #YOUR CODE HERE\n",
    "    # to consider vocabulary arguement\n",
    "    if vocabulary is None:\n",
    "      Uwords = count_word_occurrences(token_lists)\n",
    "    else:\n",
    "      Uwords = vocabulary\n",
    "\n",
    "    vocab_dict = {word: index for index, word in enumerate(sorted(Uwords))}\n",
    "    # to consider max features arguement\n",
    "    if max_features is None:\n",
    "        Uwords\n",
    "    else:\n",
    "        # If max_features is specified, get the most frequent words\n",
    "        Uwords = Uwords[:max_features]\n",
    "\n",
    "    return tf_idf(token_lists,Uwords,smoothing), vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77cc82c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word1': 0, 'word2': 0, 'word3': 0}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = ['word1', 'word2', 'word3']  # Example list of unique words\n",
    "word_counts = dict.fromkeys(unique_words, 0)\n",
    "word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ec6c5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_lists('movie_reviews_train.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62226f12-d0e5-4e74-887e-5cd852b96707",
   "metadata": {
    "id": "62226f12-d0e5-4e74-887e-5cd852b96707"
   },
   "source": [
    "We will now compare the runtime of our Tf-Idf implementation to the `sklearn` implementation. Call the respective functions with appropriate arguments in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01dded6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILE = \"movie_reviews_train.txt\"\n",
    "TEST_FILE = \"movie_reviews_test.txt\"\n",
    "\n",
    "train_corpus, y_train = get_lists(TRAIN_FILE)\n",
    "test_corpus, y_test = get_lists(TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e2e6c726-0e12-4e1f-8c8b-146a9a506a3f",
   "metadata": {
    "id": "e2e6c726-0e12-4e1f-8c8b-146a9a506a3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 21430)\n",
      "CPU times: total: 7min 57s\n",
      "Wall time: 7min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# define constants for the files we are using\n",
    "TRAIN_FILE = \"movie_reviews_train.txt\"\n",
    "TEST_FILE = \"movie_reviews_test.txt\"\n",
    "\n",
    "train_corpus, y_train = get_lists(TRAIN_FILE)\n",
    "\n",
    "# First we will use our custom vectorizer to convert words to features, and time it.\n",
    "###### YOUR CODE HERE #######\n",
    "\n",
    "train_matrix, vocab = get_tfidf_vectors(train_corpus)\n",
    "\n",
    "print(train_matrix.shape)\n",
    "# print(\"Custom--- Time taken: \", end-start, \" seconds\")\n",
    "\n",
    "# Next we will use sklearn's TfidfVectorizer to load in the data, and time it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7345c304",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 21430)\n",
      "CPU times: total: 1min 4s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_matrix,_ = get_tfidf_vectors(test_corpus, vocabulary=vocab)\n",
    "print(test_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c56b994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 22684)\n",
      "(200, 22684)\n",
      "CPU times: total: 344 ms\n",
      "Wall time: 433 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vec = TfidfVectorizer()\n",
    "train_matrix_sk = vec.fit_transform(train_corpus)\n",
    "print(train_matrix_sk.shape)\n",
    "\n",
    "\n",
    "test_matrix_sk = vec.transform(test_corpus)\n",
    "print(test_matrix_sk.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35afb9c6",
   "metadata": {},
   "source": [
    "NOTE: Ideally, your vectorizer should be within one order of magnitude of the sklearn implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8bdbf31c-bf6b-4ab4-b87b-47dd7c5468a8",
   "metadata": {
    "id": "8bdbf31c-bf6b-4ab4-b87b-47dd7c5468a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.56291122258517"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Any additional code needed to answer questions below\n",
    "sparsity = np.mean(train_matrix == 0, axis=1) * 100\n",
    "mean_custom = np.mean(sparsity)\n",
    "mean_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0ceeda9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.39492318374185"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparsity = np.mean((train_matrix_sk.toarray()) == 0, axis =1 )*100\n",
    "mean_sklearn = np.mean(sparsity)\n",
    "mean_sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6463f022-7433-4397-88ed-eed8b01b1a45",
   "metadata": {
    "id": "6463f022-7433-4397-88ed-eed8b01b1a45"
   },
   "source": [
    "1. How large is the vocabulary generated by your vectorizer?<br> **21430**\n",
    "2. How large is the vocabulary generated by the `sklearn` TfidfVectorizer?<br> **22684**\n",
    "3. Where might these differences be coming from?<br> **Preprocessing. Stemming and tokenising cause a lot of difference in word count for both the vocabularies**\n",
    "4. What steps did you take to ensure your vectorizer is optimized for best possible runtime?<br> **Tried to reduce the no. of for loops required to get the vectors**\n",
    "5. How sparse are your custom features (average percentage of features per review that are zero)?<br> **99.56**\n",
    "6. How sparse are the TfidfVectorizer's features?<br> **99.39**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38f496b",
   "metadata": {},
   "source": [
    "NOTE: if you set the lowercase option to False, the sklearn vectorizer should have a vocabulary of around 50k words/tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c9ef9db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 26373)\n",
      "(200, 26373)\n",
      "CPU times: total: 297 ms\n",
      "Wall time: 303 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vec = TfidfVectorizer(lowercase=False)\n",
    "train_matrix_sk = vec.fit_transform(train_corpus)\n",
    "print(train_matrix_sk.shape)\n",
    "\n",
    "\n",
    "test_matrix_sk = vec.transform(test_corpus)\n",
    "print(test_matrix_sk.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c76612-4dd4-489c-90e4-0c38029c32d1",
   "metadata": {
    "id": "09c76612-4dd4-489c-90e4-0c38029c32d1"
   },
   "source": [
    "**Logistic Regression**\n",
    "\n",
    "Now, we will compare how our custom features stack up against sklearn's TfidfVectorizer, by training two separate Logistic Regression classifiers - one on each set of feature vectors. Then load the test set, and convert it to two sets of feature vectors, one using our custom vectorizer (to do this, provide the vocabulary as a function argument), and one using sklearn's Tfidf (use the same object as before to transform the test inputs). For both classifiers, print the average accuracy on the test set and the F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "415934bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 21430)\n",
      "(200, 21430)\n",
      "(1600, 26373)\n",
      "(200, 26373)\n"
     ]
    }
   ],
   "source": [
    "print(train_matrix.shape)\n",
    "print(test_matrix.shape)\n",
    "print(train_matrix_sk.shape)\n",
    "print(test_matrix_sk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68eb6d36-1e71-4665-aab4-1217a42e6dcc",
   "metadata": {
    "id": "68eb6d36-1e71-4665-aab4-1217a42e6dcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUSTOM Model\n",
      "Test Accuracy: 0.54\n",
      "F1 score 0.6953642384105961\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "SKLEARN Model\n",
      "Test Accuracy: 0.785\n",
      "F1 score 0.8018433179723502\n"
     ]
    }
   ],
   "source": [
    "# First use sklearn's LogisticRegression classifier to do sentiment analysis using your custom feature vectors:\n",
    "\n",
    "###### YOUR CODE HERE #######\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Train the Model\n",
    "print(\"CUSTOM Model\")\n",
    "model = LogisticRegression()\n",
    "# print(train_matrix.shape)\n",
    "model.fit(train_matrix, y_train)\n",
    "\n",
    "# Load the test data, extract features using your custom vectorizer, and test the performance of the LR classifier\n",
    "###### YOUR CODE HERE #######\n",
    "\n",
    "y_pred_test = model.predict(test_matrix)\n",
    "\n",
    "# Print the accuracy of your model on the test data\n",
    "###### YOUR CODE HERE #######\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "score = f1_score(y_test,y_pred_test)\n",
    "print(\"F1 score\", score)\n",
    "\n",
    "# Now repeat the above steps, but this time using features extracted by sklearn's Tfidfvectorizer\n",
    "print()\n",
    "print('*'*100)\n",
    "print()\n",
    "###### YOUR CODE HERE #######\n",
    "print(\"SKLEARN Model\")\n",
    "# print(test_matrix_sk.shape)\n",
    "# print(sklearn_train_matrix.shape)\n",
    "\n",
    "skmodel = LogisticRegression()\n",
    "skmodel.fit(train_matrix_sk, y_train)\n",
    "\n",
    "y_pred_test_sk = skmodel.predict(test_matrix_sk)\n",
    "\n",
    "test_accuracy_sk = accuracy_score(y_test, y_pred_test_sk)\n",
    "print(\"Test Accuracy:\", test_accuracy_sk)\n",
    "\n",
    "score_sk = f1_score(y_test,y_pred_test_sk)\n",
    "print(\"F1 score\", score_sk)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5679888",
   "metadata": {},
   "source": [
    "NOTE: we're expecting to see a F1 score of around 80% using both your custom features and the sklearn features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0220a93-ba22-411a-962f-983ffe3a34f2",
   "metadata": {
    "id": "f0220a93-ba22-411a-962f-983ffe3a34f2"
   },
   "source": [
    "Finally, repeat the process (training and testing), but this time, set the max_features argument to 1000 for both our custom vectorizer and sklearn's Tfidfvectorizer. Report average accuracy and F1 scores for both classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f995a09c-0447-422d-8b37-e9120cfadfab",
   "metadata": {
    "id": "f995a09c-0447-422d-8b37-e9120cfadfab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUSTOM\n",
      "(1600, 1000)\n",
      "(200, 1000)\n",
      "Sklearn\n",
      "(1600, 1000)\n",
      "(200, 1000)\n",
      "\n",
      "\n",
      "Custom TFIDF Model\n",
      "Test Accuracy: 0.55\n",
      "F1 score 0.7077922077922079\n",
      "\n",
      "\n",
      "Sklearn TFIDF Model\n",
      "Test Accuracy: 0.785\n",
      "F1 score 0.8036529680365296\n",
      "CPU times: total: 31.7 s\n",
      "Wall time: 31.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "###### YOUR CODE HERE #######\n",
    "print(\"CUSTOM\")\n",
    "train_matrix_1000, vocab = get_tfidf_vectors(train_corpus, max_features=1000)\n",
    "print(train_matrix_1000.shape)\n",
    "\n",
    "test_matrix_1000,_ = get_tfidf_vectors(test_corpus, vocabulary=list(vocab.keys()),max_features=1000)\n",
    "print(test_matrix_1000.shape)\n",
    "\n",
    "print('Sklearn')\n",
    "vec = TfidfVectorizer(max_features=1000)\n",
    "train_matrix_sk_1000 = vec.fit_transform(train_corpus)\n",
    "print(train_matrix_sk_1000.shape)\n",
    "test_matrix_sk_1000 = vec.transform(test_corpus)\n",
    "print(test_matrix_sk_1000.shape)\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "# print(train_matrix.shape)\n",
    "model.fit(train_matrix_1000, y_train)\n",
    "print()\n",
    "print()\n",
    "# Load the test data, extract features using your custom vectorizer, and test the performance of the LR classifier\n",
    "###### YOUR CODE HERE #######\n",
    "\n",
    "y_pred_test = model.predict(test_matrix_1000)\n",
    "\n",
    "# Print the accuracy of your model on the test data\n",
    "###### YOUR CODE HERE #######\n",
    "print('Custom TFIDF Model')\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "score = f1_score(y_test,y_pred_test)\n",
    "print(\"F1 score\", score)\n",
    "\n",
    "# Now repeat the above steps, but this time using features extracted by sklearn's Tfidfvectorizer\n",
    "print()\n",
    "print()\n",
    "###### YOUR CODE HERE #######\n",
    "print(\"Sklearn TFIDF Model\")\n",
    "# print(test_matrix_sk.shape)\n",
    "# print(sklearn_train_matrix.shape)\n",
    "\n",
    "skmodel = LogisticRegression()\n",
    "skmodel.fit(train_matrix_sk_1000, y_train)\n",
    "\n",
    "y_pred_test_sk = skmodel.predict(test_matrix_sk_1000)\n",
    "\n",
    "test_accuracy_sk = accuracy_score(y_test, y_pred_test_sk)\n",
    "print(\"Test Accuracy:\", test_accuracy_sk)\n",
    "\n",
    "score_sk = f1_score(y_test,y_pred_test_sk)\n",
    "print(\"F1 score\", score_sk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca79b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2858e409-8a87-43aa-8646-1e5419cce6db",
   "metadata": {
    "id": "2858e409-8a87-43aa-8646-1e5419cce6db"
   },
   "source": [
    "1. Is there a stark difference between the two vectorizers with 1000 features?<br>**There is a difference between the Accuracy and the F1 scored**\n",
    "\n",
    "2. Use sklearn's documentation for the Tfidfvectorizer to figure out what may be causing the performance difference (or lack thereof).<br>**performance is likely because TFIDF vectorizers are good at identifying and using the top 1000 most important words for sentiment analysis.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68df8d77",
   "metadata": {},
   "source": [
    "NOTE: Irrespective of your conclusions, both implementations should be above 60% F1 Score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c652f8ab-3893-4021-b33f-c466b2e1d98a",
   "metadata": {
    "id": "c652f8ab-3893-4021-b33f-c466b2e1d98a"
   },
   "source": [
    "Task 3: Train a Feedforward Neural Network Model (25 points)\n",
    "----\n",
    "1. Using PyTorch, implement a feedforward neural network to do sentiment analysis. This model should take sparse vectors of length 10000 as input (note this is 10000, not 1000), and have a single output with the sigmoid activation function. The number of hidden layers, and intermediate activation choices are up to you, but please make sure your model does not take more than ~1 minute to train.\n",
    "2. Evaluate the model using PyTorch functions for average accuracy, area under the ROC curve and F1 scores (see [torcheval](https://pytorch.org/torcheval/stable/)) using both vectorizers, with max_features set to 10000 in both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "55bfe086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dataloader in c:\\users\\suyash\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f563ec2-d02a-4176-908c-011acd8851de",
   "metadata": {
    "id": "3f563ec2-d02a-4176-908c-011acd8851de"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "\tdevice = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "\tdevice = torch.device(\"cuda\")\n",
    "else:\n",
    "\tdevice = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb71198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1666cbc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c876075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class feedforward(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10000, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = torch.sigmoid(self.fc3(X))\n",
    "        return X\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            return self(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "71b4009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data using custom and sklearn vectors\n",
    "train_corpus, y_train = get_lists(TRAIN_FILE)\n",
    "test_corpus, y_test = get_lists(TEST_FILE)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_train_sklearn = vectorizer.fit_transform(train_corpus)\n",
    "X_test_sklearn = vectorizer.transform(test_corpus)\n",
    "\n",
    "X_train_custom, vocab_custom = get_tfidf_vectors(train_corpus, max_features=10000)\n",
    "X_test_custom, _ = get_tfidf_vectors(test_corpus, vocabulary=vocab_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8eea10b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with custom features\n",
      "Epoch 1/50, Loss: 0.6868590116500854\n",
      "Epoch 2/50, Loss: 0.6446149349212646\n",
      "Epoch 3/50, Loss: 0.49521809816360474\n",
      "Epoch 4/50, Loss: 0.24817170202732086\n",
      "Epoch 5/50, Loss: 0.0795406773686409\n",
      "Epoch 6/50, Loss: 0.03856183961033821\n",
      "Epoch 7/50, Loss: 0.027150766924023628\n",
      "Epoch 8/50, Loss: 0.009273674339056015\n",
      "Epoch 9/50, Loss: 0.012177294120192528\n",
      "Epoch 10/50, Loss: 0.006316666956990957\n",
      "Epoch 11/50, Loss: 0.0064244200475513935\n",
      "Epoch 12/50, Loss: 0.0033264700323343277\n",
      "Epoch 13/50, Loss: 0.003327655838802457\n",
      "Epoch 14/50, Loss: 0.0030857669189572334\n",
      "Epoch 15/50, Loss: 0.002212689258158207\n",
      "Epoch 16/50, Loss: 0.0018345618154853582\n",
      "Epoch 17/50, Loss: 0.0017266294453293085\n",
      "Epoch 18/50, Loss: 0.0014591044746339321\n",
      "Epoch 19/50, Loss: 0.0011673301924020052\n",
      "Epoch 20/50, Loss: 0.000984447542577982\n",
      "Epoch 21/50, Loss: 0.0008860075031407177\n",
      "Epoch 22/50, Loss: 0.0007502841181121767\n",
      "Epoch 23/50, Loss: 0.0009571277187205851\n",
      "Epoch 24/50, Loss: 0.0006659355130977929\n",
      "Epoch 25/50, Loss: 0.000473714986583218\n",
      "Epoch 26/50, Loss: 0.00047112361062318087\n",
      "Epoch 27/50, Loss: 0.00033704977249726653\n",
      "Epoch 28/50, Loss: 0.0003918857255484909\n",
      "Epoch 29/50, Loss: 0.00025870813988149166\n",
      "Epoch 30/50, Loss: 0.00021739628573413938\n",
      "Epoch 31/50, Loss: 0.0002173633110942319\n",
      "Epoch 32/50, Loss: 0.00020129587210249156\n",
      "Epoch 33/50, Loss: 0.00017163681332021952\n",
      "Epoch 34/50, Loss: 0.00015881267609074712\n",
      "Epoch 35/50, Loss: 0.0001490748254582286\n",
      "Epoch 36/50, Loss: 0.00011332532449159771\n",
      "Epoch 37/50, Loss: 0.00014634231047239155\n",
      "Epoch 38/50, Loss: 0.0001298719143960625\n",
      "Epoch 39/50, Loss: 0.0001147860602941364\n",
      "Epoch 40/50, Loss: 9.539072925690562e-05\n",
      "Epoch 41/50, Loss: 0.0001174277495010756\n",
      "Epoch 42/50, Loss: 7.665353768970817e-05\n",
      "Epoch 43/50, Loss: 9.027642227010801e-05\n",
      "Epoch 44/50, Loss: 6.006809780956246e-05\n",
      "Epoch 45/50, Loss: 6.6147513280157e-05\n",
      "Epoch 46/50, Loss: 4.871673081652261e-05\n",
      "Epoch 47/50, Loss: 6.623342778766528e-05\n",
      "Epoch 48/50, Loss: 6.424741150112823e-05\n",
      "Epoch 49/50, Loss: 5.707822856493294e-05\n",
      "Epoch 50/50, Loss: 3.700412707985379e-05\n",
      "\n",
      "Training model with sklearn features\n",
      "Epoch 1/50, Loss: 0.6513830423355103\n",
      "Epoch 2/50, Loss: 0.33328309655189514\n",
      "Epoch 3/50, Loss: 0.05852409824728966\n",
      "Epoch 4/50, Loss: 0.02161487005650997\n",
      "Epoch 5/50, Loss: 0.004871009383350611\n",
      "Epoch 6/50, Loss: 0.00295666279271245\n",
      "Epoch 7/50, Loss: 0.0015206490643322468\n",
      "Epoch 8/50, Loss: 0.0013693084474653006\n",
      "Epoch 9/50, Loss: 0.0009267046116292477\n",
      "Epoch 10/50, Loss: 0.0008711307309567928\n",
      "Epoch 11/50, Loss: 0.0004894271842204034\n",
      "Epoch 12/50, Loss: 0.00046932249097153544\n",
      "Epoch 13/50, Loss: 0.0003984578652307391\n",
      "Epoch 14/50, Loss: 0.00026978127425536513\n",
      "Epoch 15/50, Loss: 0.00017864519031718373\n",
      "Epoch 16/50, Loss: 0.0001799230376491323\n",
      "Epoch 17/50, Loss: 0.00017007830319926143\n",
      "Epoch 18/50, Loss: 9.165058145299554e-05\n",
      "Epoch 19/50, Loss: 0.00010729006316978484\n",
      "Epoch 20/50, Loss: 7.403628842439502e-05\n",
      "Epoch 21/50, Loss: 7.116187771316618e-05\n",
      "Epoch 22/50, Loss: 4.6934143028920516e-05\n",
      "Epoch 23/50, Loss: 4.526125849224627e-05\n",
      "Epoch 24/50, Loss: 3.1631661840947345e-05\n",
      "Epoch 25/50, Loss: 2.4359920644201338e-05\n",
      "Epoch 26/50, Loss: 2.3207741833175533e-05\n",
      "Epoch 27/50, Loss: 2.0484252672758885e-05\n",
      "Epoch 28/50, Loss: 1.8784028725349344e-05\n",
      "Epoch 29/50, Loss: 2.3698550648987293e-05\n",
      "Epoch 30/50, Loss: 1.7395703252987005e-05\n",
      "Epoch 31/50, Loss: 1.8402713976684026e-05\n",
      "Epoch 32/50, Loss: 1.3114173270878382e-05\n",
      "Epoch 33/50, Loss: 1.1501050721562933e-05\n",
      "Epoch 34/50, Loss: 1.093713399313856e-05\n",
      "Epoch 35/50, Loss: 1.0377118996984791e-05\n",
      "Epoch 36/50, Loss: 8.129480193019845e-06\n",
      "Epoch 37/50, Loss: 6.8895860749762505e-06\n",
      "Epoch 38/50, Loss: 6.059668976376997e-06\n",
      "Epoch 39/50, Loss: 7.0638898250763305e-06\n",
      "Epoch 40/50, Loss: 5.596282790065743e-06\n",
      "Epoch 41/50, Loss: 4.989948138245381e-06\n",
      "Epoch 42/50, Loss: 7.846900189178996e-06\n",
      "Epoch 43/50, Loss: 5.185132067708764e-06\n",
      "Epoch 44/50, Loss: 4.352594260126352e-06\n",
      "Epoch 45/50, Loss: 4.974874173058197e-06\n",
      "Epoch 46/50, Loss: 3.794217263930477e-06\n",
      "Epoch 47/50, Loss: 3.819460289378185e-06\n",
      "Epoch 48/50, Loss: 3.4520221561251674e-06\n",
      "Epoch 49/50, Loss: 3.033611847058637e-06\n",
      "Epoch 50/50, Loss: 3.5712278076971415e-06\n"
     ]
    }
   ],
   "source": [
    "# Train the model for 50 epochs on both custom and sklearn vectors\n",
    "\n",
    "# Function for training and evaluating the model\n",
    "def train(X_train, y_train):\n",
    "    X_train_torch = torch.tensor(X_train).float().to(device)\n",
    "    y_train_torch = torch.tensor(y_train).float().to(device)\n",
    "\n",
    "    # Create a DataLoader for the training data\n",
    "    train_data = TensorDataset(X_train_torch, y_train_torch)\n",
    "    train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "\n",
    "    # Create a feedforward neural network model\n",
    "    # you may use any activation function on the hidden layers\n",
    "    # you should use binary cross-entropy as your loss function\n",
    "    # Adam is an appropriate optimizer for this task\n",
    "    model = feedforward().to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch+1}/50, Loss: {loss.item()}')\n",
    "\n",
    "    return model\n",
    "\n",
    "print(\"Training model with custom features\")\n",
    "custom_model = train(X_train_custom, y_train)\n",
    "\n",
    "print(\"\\nTraining model with sklearn features\")\n",
    "sklearn_model = train(X_train_sklearn.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aa613b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fdf1319f-41c0-4237-982f-b60d492fbbd7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdf1319f-41c0-4237-982f-b60d492fbbd7",
    "outputId": "187d0ec2-1f99-417e-b23d-de234adb2848",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torcheval in c:\\users\\suyash\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0.7)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\suyash\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torcheval) (4.9.0)\n",
      "\n",
      "Sklearn TfidfVectorizer Model:\n",
      "Accuracy: 0.8149999976158142\n",
      "AUROC: 0.8978727694324025\n",
      "F1 Score: 0.8195121884346008\n"
     ]
    }
   ],
   "source": [
    "!pip install torcheval\n",
    "\n",
    "# Evaluate the model using custom and sklearn vectors\n",
    "# Test the model using custom and sklearn vectors\n",
    "# Evaluate the model and report the score using Binary F1 score, Binary AUROC and Binary accuracy\n",
    "\n",
    "from torcheval.metrics import BinaryAccuracy, BinaryAUROC, BinaryF1Score\n",
    "\n",
    "accuracy_metric = BinaryAccuracy()\n",
    "auroc_metric = BinaryAUROC()\n",
    "f1_metric = BinaryF1Score()\n",
    "\n",
    "# Function for evaluating the model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    X_test_torch = torch.tensor(X_test).float().to(device)\n",
    "    y_test_torch = torch.tensor(y_test).float().to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test_torch).squeeze()\n",
    "\n",
    "    # Update metric calculations\n",
    "    accuracy_metric.update(outputs, y_test_torch)\n",
    "    auroc_metric.update(outputs, y_test_torch)\n",
    "    f1_metric.update(outputs, y_test_torch)\n",
    "\n",
    "    # Compute final metrics\n",
    "    final_accuracy = accuracy_metric.compute()\n",
    "    final_auroc = auroc_metric.compute()\n",
    "    final_f1 = f1_metric.compute()\n",
    "\n",
    "    accuracy_metric.reset()\n",
    "    auroc_metric.reset()\n",
    "    f1_metric.reset()\n",
    "\n",
    "    return final_accuracy.item(), final_auroc.item(), final_f1.item()\n",
    "\n",
    "\n",
    "print(\"\\nSklearn TfidfVectorizer Model:\")\n",
    "print(\"Accuracy:\", sklearn_accuracy)\n",
    "print(\"AUROC:\", sklearn_auroc)\n",
    "print(\"F1 Score:\", sklearn_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08d71ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_accuracy, custom_auroc, custom_f1 = evaluate_model(custom_model, X_test_custom, y_test)\n",
    "\n",
    "print(\"Custom TF-IDF Model:\")\n",
    "print(\"Accuracy:\", custom_accuracy)\n",
    "print(\"AUROC:\", custom_auroc)\n",
    "print(\"F1 Score:\", custom_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a332b6",
   "metadata": {},
   "source": [
    "NOTE: As in the last task, we're expecting to see a F1 score of over 60% using both your custom features and the sklearn features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b269ee9",
   "metadata": {
    "id": "8b269ee9"
   },
   "source": [
    "5 points in this assignment are reserved for overall style (both for writing and for code submitted). All work submitted should be clear, easily interpretable, and checked for spelling, etc. (Re-read what you write and make sure it makes sense). Course staff are always happy to give grammatical help (but we won't pre-grade the content of your answers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f50477f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
